{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Problem Set\n",
    "\n",
    "### Problem 1:\n",
    "\n",
    "Show that maximizing the margin is the same as minimizing the norm of the weight vector.\n",
    "\n",
    "### Solution:\n",
    "\n",
    "We have a plane that separates our data set, given by:\n",
    "$$ w^Tx_{i} + b = 0 $$\n",
    "and inequalities: \n",
    "$$ w^Tx_{i} +b >= 1 \\quad \\quad \\text {if $y_i = 1$} $$\n",
    "$$ w^Tx_{i} +b <= -1 \\quad \\quad \\text {if $y_i = -1$} $$\n",
    "\n",
    "the last two inequalities can be expressed as:\n",
    "$$ y_{i}(w^Tx_{i} +b) >= 1$$\n",
    "\n",
    "this means that if we take a $x_{i}$ that lies at the decision boundary we have:\n",
    "$$ y_{i}(w^Tx_{i} +b) - 1 = 0 \\quad \\quad (1)$$ \n",
    "\n",
    "Remember that what we are trying to do is to maximize the width of the hyperplane that separates our two classes.\n",
    "Lets assume we have to vectors $x_{a}$ and $x_{b}$ such that $x_{a}$ lies at the decision boundry between the hyperplane and our negative class and $x_{b}$ lies at the decision boundry between the hyperplane and our positive class. That means that subsititing on $(1)$:\n",
    "$$ w^Tx_a = -(1 + b) \\quad \\quad (2)$$\n",
    "$$ w^Tx_b = 1 - b \\quad \\quad (3)$$\n",
    "\n",
    "Now, the Width of the hyperplane can be computed as follows:\n",
    "$$ Width = (x_{b} - x_{a}) . \\hat{u} \\quad \\quad \\text{where $\\hat{u}$ is a unit vector}$$\n",
    "\n",
    "and we know that $w$ vector is a normal vector with respect to the hyperplane, we normalize $w$ to obtain the unit vector $\\hat{w}$. Therefore:\n",
    "$$Width = (x_{b} - x_{a}).\\frac{w}{||w||}$$\n",
    "\n",
    "Using (2) and (3) we simplify the width expression to:\n",
    "$$Width = \\frac{2}{||w||}$$\n",
    "\n",
    "If we intend to maximize $\\frac{2}{||w||}$, that means we need to minimize the denominator of that expression, therefore we can express the problem as a minimization of $||w||$, which is the same problem as: \n",
    "$$\\text{Minimize $(||w||)^{2}$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:\n",
    "\n",
    "Derive the dual formulation of SVM from the primal form using Lagrange multipliers-ignore slack variables.\n",
    "\n",
    "### Solution:\n",
    "\n",
    "To solve the constrained optimization problem in SVMs we introcude the Lagrange multipliers $a_n$ so that $a_n >= 0$. This gives us the equation:\n",
    "$$ L(w, b, a) = \\frac{||w||^2}{2} - \\sum_{i=1}^n a_i (y_i(w^Tx_i +b) - 1) \\quad \\quad (1)$$\n",
    "\n",
    "Then we compute the derivates of $L$ with respect to $w$ and $b$. \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial{L(w, b, a)}}{\\partial{w}} = w - \\sum_{i=1}^n a_iy_ix_i \\\\\n",
    "\\frac{\\partial{L(w, b, a)}}{\\partial{b}} = -\\sum_{i=1}^n a_iy_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we equal both derivates to $0$ we find that:\n",
    "$$\n",
    "\\begin{align}\n",
    "w = \\sum_{i=1}^n a_iy_ix_i \\quad \\quad (2)\\\\ \n",
    "\\sum_{i=1}^n a_iy_i = 0 \\quad \\quad (3)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we sustitute $(2)$ our findings in $(1)$:\n",
    "$$\n",
    "\\begin{align}\n",
    "L(w, b, a) = \\frac{||\\sum_{i=1}^n a_iy_ix_i||^2}{2} - \\sum_{i=1}^n a_i(y_i((\\sum_{j=1}^n a_jy_jx_j)xi + b) - 1) \\quad \\quad \\quad \\quad\\\\\n",
    "L(w, b, a) = \\frac{1}{2}\\sum_{i=1}^n a_iy_ix_i\\sum_{j=1}^n a_jy_jx_j - \\sum_{i=1}^n a_iy_ix_i\\sum_{j=1}^n a_jy_jx_j - b\\sum_{i=1}^n a_iy_i + \\sum_{i=1}^n a_i \\quad \\quad \\text{by (3) we see that our 3rd term is 0} \\\\\n",
    "L(w, b, a) = \\sum_{i=1}^n a_i - \\frac{1}{2}\\sum_{i=1}^n a_iy_ix_i\\sum_{j=1}^n a_jy_jx_j \\quad \\quad \\text{Which is the dual formulation of SVM}\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3:\n",
    "\n",
    "Assume the linear kernel is replaced by a Radial Basis Function (RBF) kernel. How does the decision value $\\hat{y} in slide 43 change?\n",
    "\n",
    "### Solution:\n",
    "\n",
    "On slide 43 the $\\hat{y}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = sign(\\sum_{i \\in SV}\\hat{\\alpha_i}y_i(x_i^Tx) + b)\n",
    "$$\n",
    "\n",
    "If instead we use a Radial Basis Function as kernel of the form $K(\\vec{a}, \\vec{b}) = e^{-\\gamma[\\vec{a} - \\vec{b}]^2}$ we end up with with the following:\n",
    "\n",
    "$$\n",
    "\\hat{y} = sign(\\sum_{i \\in SV}\\hat{\\alpha_i}y_i(e^{-\\gamma[x_i - x]^2}) + b)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4:\n",
    "\n",
    "Download the 20Newsgroup dataset here: http://ana.cachopo.org/datasets-for-single-label-text-categorization and use the 20ng-train-no-stop.txt and 20ng-test-no-stop.txt versions (No stop words). Take only the lines corresponding to rec.sport.baseball & alt.atheism in both train and test set. Train a binary linear SVM classifier (set solver to 1 ) using liblinear on the above data.\n",
    "\n",
    "Plot a graph that shows how the training and test error (misclassification rate) vary as a function of the parameter C [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "Attempt to improve the classification error from the best known C setting from above and report on what worked.\t\n",
    "\n",
    "### Solution:\n",
    "\n",
    "We downloaded the pointed data set and filtered all lines to have only classes `rec.sport.baseball` `alt.atheism`. After filtering this are the number of points for each training and test sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     716 20ng-test-no-stop-filtered.txt\n",
      "    1077 20ng-train-no-stop-filtered.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l 20ng-test-no-stop-filtered.txt\n",
    "!wc -l 20ng-train-no-stop-filtered.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1077 text corpus for the train set and 716 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to transform the data to the libsvm format to feed our data sets to `train` and `predict`.\n",
    "\n",
    "Lets import all needed libraries and load the filtered data sets into matrices with two coloums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# for this case we are encoding rec.sport.baseball as 1\n",
    "# and alt.atheism\n",
    "def encode_labels(data):\n",
    "    return [1 if y == \"rec.sport.baseball\" else 0 for y in data]\n",
    "\n",
    "train_file = \"./20ng-train-no-stop-filtered.txt\"\n",
    "test_file = \"./20ng-test-no-stop-filtered.txt\"\n",
    "\n",
    "data = {}\n",
    "data['train'] = np.loadtxt(train_file, dtype=np.str, delimiter='\\t')\n",
    "data['test'] = np.loadtxt(test_file, dtype=np.str, delimiter='\\t')\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For transforming the documents to numerical features we used a Tf-Id transformer included in `sklearn` that will translate our texts into numerical features. Another technique that we could have used is to simply vectorize each document ( we tokenize the documents and count how many times a given token appears in each document ), if we would feed our classifier with this counts it could be that the tokens that appear much ( probably carrying not much info ) would shadow the ones that appear less ( the ones that probably have much more information ). A Tf-Id transformer takes into account the frequency of a token in the whole document to avoid that.\n",
    "\n",
    "We proceed then to transform the data and dump it into the desired libsvm format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "vectorizerOne = TfidfVectorizer()\n",
    "\n",
    "# transform train data set\n",
    "X_train = vectorizerOne.fit_transform(data['train'][:, 1])\n",
    "# transform test data set\n",
    "X_test = vectorizerOne.transform(data['test'][:, 1])\n",
    "\n",
    "# Enconding the labels to 1 and 0\n",
    "y_train = encode_labels(data['train'][:, 0])\n",
    "y_test = encode_labels(data['test'][:, 0])\n",
    "\n",
    "# we dump all into libsvm files.\n",
    "dump_svmlight_file(X_train, y_train, train_file + \".libsvm\", zero_based=False)\n",
    "dump_svmlight_file(X_test, y_test, test_file + \".libsvm\", zero_based=False)\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data sets in the desired format, we proceed to train different models with different values of C (Which controls the trade-off errors on training set and margin maximization for low training error and a low testing error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using C=0.01\n",
      "\n",
      "optimization finished, #iter = 3\n",
      "Objective value = -8.935943\n",
      "nSV = 1077\n",
      "Accuracy = 97.7654% (700/716)\n",
      "Test Error: 0.0223463687151\n",
      "Accuracy = 99.8143% (1075/1077)\n",
      "Training Error: 0.00185701021356\n",
      "\n",
      "using C=0.1\n",
      "*\n",
      "optimization finished, #iter = 6\n",
      "Objective value = -40.983291\n",
      "nSV = 1042\n",
      "Accuracy = 98.324% (704/716)\n",
      "Test Error: 0.0167597765363\n",
      "Accuracy = 100% (1077/1077)\n",
      "Training Error: 0.0\n",
      "\n",
      "using C=1\n",
      "*\n",
      "optimization finished, #iter = 7\n",
      "Objective value = -85.363532\n",
      "nSV = 720\n",
      "Accuracy = 98.8827% (708/716)\n",
      "Test Error: 0.0111731843575\n",
      "Accuracy = 100% (1077/1077)\n",
      "Training Error: 0.0\n",
      "\n",
      "using C=10\n",
      "*\n",
      "optimization finished, #iter = 9\n",
      "Objective value = -103.255425\n",
      "nSV = 581\n",
      "Accuracy = 99.0223% (709/716)\n",
      "Test Error: 0.00977653631285\n",
      "Accuracy = 100% (1077/1077)\n",
      "Training Error: 0.0\n",
      "\n",
      "using C=100\n",
      "*\n",
      "optimization finished, #iter = 9\n",
      "Objective value = -105.848246\n",
      "nSV = 561\n",
      "Accuracy = 99.162% (710/716)\n",
      "Test Error: 0.00837988826816\n",
      "Accuracy = 100% (1077/1077)\n",
      "Training Error: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./errors-for-C.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing the error between our classification and real labels, the following code is used:\n",
    "```\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "data_file = sys.argv[1]\n",
    "output = sys.argv[2]\n",
    "\n",
    "y_pred = load_svmlight_file(data_file)[1]\n",
    "y = np.loadtxt(output)\n",
    "\n",
    "#If predicted labels are equal then 0\n",
    "#If they differ then 1 meaniing that we count an error.\n",
    "\n",
    "result = np.logical_xor(y_pred, y)\n",
    "print (1.0/len(result))*sum(result)\n",
    "```\n",
    "\n",
    "From the output we can see that we endup having the following table:\n",
    "\n",
    "| C    |  Test Error      |  Train Error     |\n",
    "|------|:----------------:|-----------------:|\n",
    "| 0.01 |  0.0223463687151 | 0.00185701021356 |\n",
    "| 0.1  |  0.0167597765363 | 0.0 |\n",
    "| 1    |  0.0111731843575 | 0.0 |\n",
    "| 10   | 0.00977653631285 | 0.0 |\n",
    "| 100  | 0.00837988826816 | 0.0 |\n",
    "\n",
    "If we plot the errors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAF/CAYAAAC8IEhIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dfc1c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.array([[0.01, 0.0223463687151, 0.00185701021356], [0.1, 0.0167597765363, 0.0],\n",
    "                [1, 0.0111731843575, 0.0], [10, 0.00977653631285, 0.0 ], [100, 0.00837988826816, 0.0]])\n",
    "\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Errors\")\n",
    "\n",
    "x = data[:, 0]\n",
    "test_error = data[:, 1]\n",
    "train_error = data[:, 2]\n",
    "\n",
    "plt.semilogx(x, test_error, \n",
    "             basex=10,\n",
    "             color='darkred', \n",
    "             linewidth = 0.5, label='Test Error')\n",
    "plt.semilogx(x, train_error, \n",
    "             basex=10,\n",
    "             color='green', \n",
    "             linewidth = 0.5, label='Training Error')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the test error reduces as we increase C. Test Error reduces as a consequence of us penalizing more and more the wrong classification done by the model. The training error goes down to 0 as soon as we use C = 0.1. \n",
    "\n",
    "Given this results, we choose to use a C value of **100**. \n",
    "\n",
    "On the test set we get: \n",
    "\n",
    "`Accuracy = 99.162% (710/716)\n",
    "Test Error: 0.00837988826816\n",
    "Accuracy = 100% (1077/1077)\n",
    "Training Error: 0.0`\n",
    "\n",
    "And on the training set we get:\n",
    "\n",
    "`Accuracy = 100% (1077/1077)\n",
    "Training Error: 0.0`\n",
    "\n",
    "After experimenting with the Vectorizer we use to transform our text, we discovered that a way of improving the Accuracy and hence the Test Error is to use a sublinear tf scaling. Instead of using the term frequency, we use its logarithm. The idea behind this scaling is that it is commonly the case that if a token appears x times in a document, it is unlikely that it carries x times the significance of 1 occurrence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# for this case we are encoding rec.sport.baseball as 1\n",
    "# and alt.atheism\n",
    "def encode_labels(data):\n",
    "    return [1 if y == \"rec.sport.baseball\" else 0 for y in data]\n",
    "\n",
    "train_file = \"./20ng-train-no-stop-filtered.txt\"\n",
    "test_file = \"./20ng-test-no-stop-filtered.txt\"\n",
    "\n",
    "data = {}\n",
    "data['train'] = np.loadtxt(train_file, dtype=np.str, delimiter='\\t')\n",
    "data['test'] = np.loadtxt(test_file, dtype=np.str, delimiter='\\t')\n",
    "\n",
    "# max_df 0.5\n",
    "# sublinear_tf=True\n",
    "vectorizerOne = TfidfVectorizer(sublinear_tf=True)\n",
    "X_train = vectorizerOne.fit_transform(data['train'][:, 1])\n",
    "\n",
    "#vectorizerTwo = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=\"english\")\n",
    "X_test = vectorizerOne.transform(data['test'][:, 1])\n",
    "\n",
    "y_train = encode_labels(data['train'][:, 0])\n",
    "y_test = encode_labels(data['test'][:, 0])\n",
    "\n",
    "# we dump all into libsvm files.\n",
    "dump_svmlight_file(X_train, y_train, train_file + \".libsvm\", zero_based=False)\n",
    "dump_svmlight_file(X_test, y_test, test_file + \".libsvm\", zero_based=False)\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using C=100\n",
      "*\n",
      "optimization finished, #iter = 8\n",
      "Objective value = -104.958603\n",
      "nSV = 593\n",
      "Accuracy = 99.4413% (712/716)\n",
      "Test Error: 0.00558659217877\n",
      "Accuracy = 100% (1077/1077)\n",
      "Training Error: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./errors-for-100.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvements\n",
    "\n",
    "Our Accuracy and Test Error improve from: \n",
    "`Accuracy = 99.162% (710/716)\n",
    "Test Error: 0.00837988826816`\n",
    "\n",
    "to \n",
    "\n",
    "`Accuracy = 99.4413% (712/716)\n",
    "Test Error: 0.00558659217877`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Add a third class to the above two (rec.motorcycles). Now given a new datapoint you want to classify it as belonging to one of the three classes:\n",
    "\n",
    "* How would you adapt the binary SVM to solve this 3-class problem\n",
    "* Report on the number of positive/negative examples in the training data for each of those adaptations?\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "In this case we use the text for classes `rec.motorcycles, rec.sport.baseball, alt.atheism`.\n",
    "\n",
    "To solve this, we present two appraoaches: \n",
    "\n",
    "### Approach 1: One vs. The rest\n",
    "\n",
    "For this solution we have to train 3 2-class SVMs. Each SVM will mark one of the classes as the possitive and the other two as negative. We then combine the output of all 3 SVMs as follows: \n",
    "\n",
    "$$ y(x) = max_x y_k(x) $$\n",
    "\n",
    "Taking the max of the results of all 3 SVMs.\n",
    "\n",
    "One of the problems of this approach is that the training sets might end up unballanced. For our training dataset we end up with the following distribution of positive/negative observations: \n",
    "\n",
    "Total of observations: 1675.\n",
    "\n",
    "| SMV: Posstive class | SVM: Negative classes | Possitive observations - % | Negative observations - % |\n",
    "|:----|:----|-----:|-----:|\n",
    "| alt.atheism        | rec.motorcycles, rec.sport.baseball | 480 - 28.6% | 1195 - 71.4% |\n",
    "| rec.motorcycles    | alt.atheism, rec.sport.baseball     | 598 - 35.7% | 1077 - 64.3% |\n",
    "| rec.sport.baseball | alt.atheism, rec.motorcycles        | 597 - 35.6  | 1078 - 64.4% |\n",
    "\n",
    "We see that the positive class has in all 3 SVMs end up being considerably less.\n",
    "\n",
    "### Approach 2: One vs One\n",
    "\n",
    "Here, we train again 3 different 2-class SVMs, on all possible pair of classes. To classify test points the class with highest number of votes among all 3 SVMs wins.\n",
    "\n",
    "We then have to construct 3 SVMs for which the following distribution of positive/negative observations is seen:\n",
    "\n",
    "| SMV: Posstive class | SMV: Negative class | Possitive observations - % | Negative observations - % |\n",
    "|:----|:----|-----:|-----:|\n",
    "| alt.atheism        | rec.motorcycles |480 - 44.5% | 598 - 55.5% |\n",
    "| rec.motorcycles    | rec.sport.baseball | 598 - 50.0% | 597 - 50.0% |\n",
    "| rec.sport.baseball | alt.atheism | 597 - 55.4  | 480 - 44.6% |\n",
    "\n",
    "This approach will use a  more balanced number of possitve/negative observations to train each of the SMVs, which will perform better as the approach listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
